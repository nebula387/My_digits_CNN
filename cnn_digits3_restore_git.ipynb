{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce788329",
   "metadata": {},
   "source": [
    "# Распознавание рукописных цифр\n",
    "В данной работе напишу нейронку на базе Pytorch CNN для распознавания собственных рукописных цифр. Сложность в том что, обученная сеть на MNIST на моих цифрах показывает низкие результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Python3\\PyIntel\\img_transform\\Digits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd()) # current way\n",
    "# directory = os.path.join(os.path.dirname(__file__), \"my_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da01403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06353c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: xpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# xpu\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79df02",
   "metadata": {},
   "source": [
    "## Model\n",
    "здесь в результате тестов подобрана максимально эффективная модель для моих рукописных цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9faa5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model2 = nn.Sequential(\n",
    "    nn.Conv2d(3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2), # batch, out, 7, 7\n",
    "\n",
    "    nn.Flatten(1), # batch, out\n",
    "    nn.Linear(32*7*7, 32, bias=False),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(32, 32, bias=False),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(32, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  (15): Linear(in_features=1568, out_features=32, bias=False)\n",
       "  (16): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Linear(in_features=32, out_features=32, bias=False)\n",
       "  (19): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = conv_model2\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adee7d0",
   "metadata": {},
   "source": [
    "### формирование обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b4c515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = tfs.Compose([tfs.ToImage(),\n",
    "                          tfs.ToDtype(torch.float32, scale=True),\n",
    "                          ])\n",
    "\n",
    "d_train = ImageFolder(\"dataset/train\", transform=transforms)\n",
    "train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
    "\n",
    "x_, y_ = next(iter(train_data))\n",
    "x_[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb42cda",
   "metadata": {},
   "source": [
    "### train \n",
    "обучение и сохранение весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d2f9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], loss_mean=0.174: 100%|██████████| 1875/1875 [00:41<00:00, 44.65it/s]\n",
      "Epoch [2/30], loss_mean=0.050: 100%|██████████| 1875/1875 [00:42<00:00, 44.05it/s]\n",
      "Epoch [3/30], loss_mean=0.038: 100%|██████████| 1875/1875 [00:42<00:00, 44.32it/s]\n",
      "Epoch [4/30], loss_mean=0.030: 100%|██████████| 1875/1875 [00:42<00:00, 44.36it/s]\n",
      "Epoch [5/30], loss_mean=0.027: 100%|██████████| 1875/1875 [00:42<00:00, 44.04it/s]\n",
      "Epoch [6/30], loss_mean=0.022: 100%|██████████| 1875/1875 [00:42<00:00, 44.28it/s]\n",
      "Epoch [7/30], loss_mean=0.020: 100%|██████████| 1875/1875 [00:42<00:00, 44.20it/s]\n",
      "Epoch [8/30], loss_mean=0.018: 100%|██████████| 1875/1875 [00:40<00:00, 46.18it/s]\n",
      "Epoch [9/30], loss_mean=0.015: 100%|██████████| 1875/1875 [00:39<00:00, 47.31it/s]\n",
      "Epoch [10/30], loss_mean=0.014: 100%|██████████| 1875/1875 [00:39<00:00, 47.08it/s]\n",
      "Epoch [11/30], loss_mean=0.012: 100%|██████████| 1875/1875 [00:39<00:00, 47.41it/s]\n",
      "Epoch [12/30], loss_mean=0.012: 100%|██████████| 1875/1875 [00:39<00:00, 47.17it/s]\n",
      "Epoch [13/30], loss_mean=0.011: 100%|██████████| 1875/1875 [00:39<00:00, 47.16it/s]\n",
      "Epoch [14/30], loss_mean=0.009: 100%|██████████| 1875/1875 [00:39<00:00, 47.31it/s]\n",
      "Epoch [15/30], loss_mean=0.010: 100%|██████████| 1875/1875 [00:40<00:00, 46.49it/s]\n",
      "Epoch [16/30], loss_mean=0.008: 100%|██████████| 1875/1875 [00:40<00:00, 46.58it/s]\n",
      "Epoch [17/30], loss_mean=0.009: 100%|██████████| 1875/1875 [00:41<00:00, 45.21it/s]\n",
      "Epoch [18/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:42<00:00, 43.88it/s]\n",
      "Epoch [19/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:42<00:00, 43.89it/s]\n",
      "Epoch [20/30], loss_mean=0.006: 100%|██████████| 1875/1875 [00:42<00:00, 43.96it/s]\n",
      "Epoch [21/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:41<00:00, 45.16it/s]\n",
      "Epoch [22/30], loss_mean=0.005: 100%|██████████| 1875/1875 [00:41<00:00, 44.83it/s]\n",
      "Epoch [23/30], loss_mean=0.006: 100%|██████████| 1875/1875 [00:41<00:00, 45.40it/s]\n",
      "Epoch [24/30], loss_mean=0.006: 100%|██████████| 1875/1875 [00:41<00:00, 45.34it/s]\n",
      "Epoch [25/30], loss_mean=0.005: 100%|██████████| 1875/1875 [00:41<00:00, 45.11it/s]\n",
      "Epoch [26/30], loss_mean=0.005: 100%|██████████| 1875/1875 [00:41<00:00, 45.28it/s]\n",
      "Epoch [27/30], loss_mean=0.005: 100%|██████████| 1875/1875 [00:41<00:00, 45.39it/s]\n",
      "Epoch [28/30], loss_mean=0.005: 100%|██████████| 1875/1875 [00:41<00:00, 45.35it/s]\n",
      "Epoch [29/30], loss_mean=0.004: 100%|██████████| 1875/1875 [00:41<00:00, 45.29it/s]\n",
      "Epoch [30/30], loss_mean=0.005: 100%|██████████| 1875/1875 [00:40<00:00, 46.51it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "epochs = 30\n",
    "model.train()\n",
    "\n",
    "for _e in range(epochs):\n",
    "    loss_mean = 0\n",
    "    lm_count = 0\n",
    "\n",
    "    train_tqdm = tqdm(train_data, leave=True)\n",
    "    for x_train, y_train in train_tqdm:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        predict = model(x_train)\n",
    "        loss = loss_function(predict, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lm_count += 1\n",
    "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "        train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575398e",
   "metadata": {},
   "source": [
    "## Restore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61bace93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# torch.save(model.state_dict(), f'model_1_weight_{int(Q*10000)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5237baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_weight_9930.pth', map_location='xpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967dbc0",
   "metadata": {},
   "source": [
    "### test\n",
    "результаты теста на обучающей выбрке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbb7619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946\n"
     ]
    }
   ],
   "source": [
    "d_test = ImageFolder(\"dataset/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test, batch_size=500, shuffle=False)\n",
    "\n",
    "Q = 0\n",
    "\n",
    "# тестирование обученной НС\n",
    "model.eval()\n",
    "\n",
    "for x_test, y_test in test_data:\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    with torch.no_grad():\n",
    "        p = model(x_test)\n",
    "        p = torch.argmax(p, dim=1)\n",
    "        Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3bae328",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfs.Compose([\n",
    "    tfs.ToImage(),\n",
    "    tfs.Resize((28, 28)),                  # подгоняем под MNIST\n",
    "    tfs.RandomInvert(p=1.0),               # инвертируем цвет\n",
    "    tfs.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "# transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed6cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(\"images/im_2.png\")\n",
    "# img = img.convert(\"RGB\")\n",
    "# img = img.resize((28, 28))\n",
    "# # tr = tfs.Compose([tfs.RandomInvert(p=1.0), tfs.Grayscale()])\n",
    "# tr = tfs.Compose([tfs.RandomInvert(p=1.0)])\n",
    "# img = tr(img)\n",
    "# img = transform(img)\n",
    "# img = img.to(device)\n",
    "# torch.argmax(model(img.unsqueeze(0)).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970be5f7",
   "metadata": {},
   "source": [
    "### test\n",
    "тест на моих цифрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb650a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res\n",
    "        \n",
    "    \n",
    "res_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa710745",
   "metadata": {},
   "source": [
    "просмотр уверенности модели в предсказаниии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac24f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([  5.1438,  -5.5931,  -4.6117, -14.3769,  -6.4987,  -8.8049,  -3.0568,\n",
      "         -2.0799,  -8.2567,  -7.7662], device='xpu:0')\n",
      "1 tensor([-18.0151,   6.8636, -13.7433, -18.1379, -15.1786, -13.8746, -13.2797,\n",
      "          0.1517,  -9.6195, -14.0596], device='xpu:0')\n",
      "2 tensor([-12.8619,  -8.9557,  12.7133, -13.1203,  -9.6874, -18.5373, -13.9622,\n",
      "         -6.6759,  -5.9096,  -9.3503], device='xpu:0')\n",
      "3 tensor([-12.5446,  -6.9928,  -9.6180,   9.1124, -13.5135,  -6.9957, -14.4150,\n",
      "         -2.0937, -19.3546, -16.2413], device='xpu:0')\n",
      "4 tensor([ -8.7306,  -9.5899, -13.1923, -16.4296,  10.5303, -10.5634,  -6.9361,\n",
      "         -8.6767, -14.9485,  -5.9290], device='xpu:0')\n",
      "5 tensor([-14.7821, -10.3882, -17.2775, -11.1291, -14.9441,  13.0621,  -6.5978,\n",
      "        -10.1905, -14.7512, -11.9467], device='xpu:0')\n",
      "6 tensor([ -4.6542,  -6.5027, -12.8920, -16.1850,  -7.9885,   1.8468,   4.4932,\n",
      "         -5.7202,  -7.7378,  -5.8056], device='xpu:0')\n",
      "7 tensor([-25.2367,  -3.2251,  -7.8446, -14.1211, -12.7105, -18.4078, -13.5542,\n",
      "          6.7819,  -7.7815, -16.5538], device='xpu:0')\n",
      "8 tensor([ -9.4855, -10.7899, -12.3323, -11.0131, -11.9966, -11.9490,  -8.3622,\n",
      "        -12.8610,  11.3698,  -5.9607], device='xpu:0')\n",
      "9 tensor([ -9.4678,  -4.5585,  -5.3087,  -7.2976,   1.4618,  -3.5740, -11.6576,\n",
      "         -5.4854,  -8.5156,   2.6067], device='xpu:0')\n"
     ]
    }
   ],
   "source": [
    "# просмотр уверенности модели в предсказаниии\n",
    "\n",
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        print(i, res)\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df819db6",
   "metadata": {},
   "source": [
    "В результате ряда экспериментов подобрана модель и приведен пример распознавания цифр не из обучающей выборки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
