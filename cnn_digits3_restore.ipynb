{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce788329",
   "metadata": {},
   "source": [
    "# Распознавание рукописных цифр\n",
    "В данной работе напишу нейронку на базе Pytorch CNN для распознавания собственных рукописных цифр. Сложность в том что, обученная сеть на MNIST на моих цифрах показывает низкие результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Python3\\PyIntel\\img_transform\\Digits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd()) # current way\n",
    "# directory = os.path.join(os.path.dirname(__file__), \"my_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da01403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552eb037",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.xpu.is_available():\n",
    "    device = 'xpu' # intel inside)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79df02",
   "metadata": {},
   "source": [
    "## Model\n",
    "здесь в результате тестов подобрана максимально эффективная модель для моих рукописных цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9faa5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model2 = nn.Sequential(\n",
    "    nn.Conv2d(3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(32, out_channels=20, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(20),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2), # batch, out, 7, 7\n",
    "\n",
    "    nn.Flatten(1), # batch, 980\n",
    "    nn.Linear(20*7*7, 16, bias=False),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(16, 16, bias=False),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(16, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (11): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  (15): Linear(in_features=980, out_features=16, bias=False)\n",
       "  (16): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Linear(in_features=16, out_features=16, bias=False)\n",
       "  (19): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = conv_model2\n",
    "model.xpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adee7d0",
   "metadata": {},
   "source": [
    "### формирование обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4c515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = tfs.Compose([tfs.ToImage(),\n",
    "                          tfs.ToDtype(torch.float32, scale=True),\n",
    "                          ])\n",
    "\n",
    "d_train = ImageFolder(\"dataset/train\", transform=transforms)\n",
    "train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
    "\n",
    "x_, y_ = next(iter(train_data))\n",
    "x_[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb42cda",
   "metadata": {},
   "source": [
    "### train \n",
    "обучение и сохранение весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2f9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/8], loss_mean=0.141: 100%|██████████| 1875/1875 [00:40<00:00, 45.86it/s]\n",
      "Epoch [2/8], loss_mean=0.064: 100%|██████████| 1875/1875 [00:39<00:00, 47.35it/s]\n",
      "Epoch [3/8], loss_mean=0.051: 100%|██████████| 1875/1875 [00:40<00:00, 46.54it/s]\n",
      "Epoch [4/8], loss_mean=0.046: 100%|██████████| 1875/1875 [00:38<00:00, 48.48it/s]\n",
      "Epoch [5/8], loss_mean=0.040: 100%|██████████| 1875/1875 [00:38<00:00, 48.58it/s]\n",
      "Epoch [6/8], loss_mean=0.034: 100%|██████████| 1875/1875 [00:38<00:00, 48.95it/s]\n",
      "Epoch [7/8], loss_mean=0.031: 100%|██████████| 1875/1875 [00:38<00:00, 48.45it/s]\n",
      "Epoch [8/8], loss_mean=0.028: 100%|██████████| 1875/1875 [00:38<00:00, 48.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# epochs = 8\n",
    "# model.train()\n",
    "\n",
    "# for _e in range(epochs):\n",
    "#     loss_mean = 0\n",
    "#     lm_count = 0\n",
    "\n",
    "#     train_tqdm = tqdm(train_data, leave=True)\n",
    "#     for x_train, y_train in train_tqdm:\n",
    "#         x_train = x_train.xpu()\n",
    "#         y_train = y_train.xpu()\n",
    "#         predict = model(x_train)\n",
    "#         loss = loss_function(predict, y_train)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         lm_count += 1\n",
    "#         loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "#         train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575398e",
   "metadata": {},
   "source": [
    "## Restore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5237baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weight_9930.pth', map_location='xpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967dbc0",
   "metadata": {},
   "source": [
    "### test\n",
    "результаты теста на обучающей выбрке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb7619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993\n"
     ]
    }
   ],
   "source": [
    "d_test = ImageFolder(\"dataset/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test, batch_size=500, shuffle=False)\n",
    "\n",
    "Q = 0\n",
    "\n",
    "# тестирование обученной НС\n",
    "model.eval()\n",
    "\n",
    "for x_test, y_test in test_data:\n",
    "    x_test = x_test.xpu()\n",
    "    y_test = y_test.xpu()\n",
    "    with torch.no_grad():\n",
    "        p = model(x_test)\n",
    "        p = torch.argmax(p, dim=1)\n",
    "        Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3bae328",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfs.Compose([\n",
    "    tfs.ToImage(),\n",
    "    tfs.Resize((28, 28)),                  # подгоняем под MNIST\n",
    "    tfs.RandomInvert(p=1.0),               # инвертируем цвет\n",
    "    tfs.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "# transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='xpu:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = Image.open(\"images/im_2.png\")\n",
    "# img = img.convert(\"RGB\")\n",
    "# img = img.resize((28, 28))\n",
    "# # tr = tfs.Compose([tfs.RandomInvert(p=1.0), tfs.Grayscale()])\n",
    "# tr = tfs.Compose([tfs.RandomInvert(p=1.0)])\n",
    "# img = tr(img)\n",
    "# img = transform(img)\n",
    "# img = img.to(device)\n",
    "# torch.argmax(model(img.unsqueeze(0)).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970be5f7",
   "metadata": {},
   "source": [
    "### test\n",
    "тест на моих цифрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb650a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res\n",
    "        \n",
    "    \n",
    "res_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa710745",
   "metadata": {},
   "source": [
    "В результате ряда экспериментов подобрана модель и приведен пример распознавания цифр не из обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24f9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
