{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce788329",
   "metadata": {},
   "source": [
    "# Распознавание рукописных цифр\n",
    "В данной работе напишу нейронку на базе Pytorch CNN для распознавания собственных рукописных цифр. Сложность в том что, обученная сеть на MNIST на моих цифрах показывает низкие результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Python3\\PyIntel\\img_transform\\Digits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd()) # current way\n",
    "# directory = os.path.join(os.path.dirname(__file__), \"my_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da01403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06353c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: xpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# xpu\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79df02",
   "metadata": {},
   "source": [
    "## Model\n",
    "здесь в результате тестов подобрана максимально эффективная модель для моих рукописных цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9faa5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model2 = nn.Sequential(\n",
    "    nn.Conv2d(3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(32, out_channels=20, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(20),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2), # batch, out, 7, 7\n",
    "\n",
    "    nn.Flatten(1), # batch, 980\n",
    "    nn.Linear(20*7*7, 16, bias=False),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(16, 16, bias=False),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(16, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (11): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  (15): Linear(in_features=980, out_features=16, bias=False)\n",
       "  (16): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Linear(in_features=16, out_features=16, bias=False)\n",
       "  (19): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = conv_model2\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adee7d0",
   "metadata": {},
   "source": [
    "### формирование обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b4c515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = tfs.Compose([tfs.ToImage(),\n",
    "                          tfs.ToDtype(torch.float32, scale=True),\n",
    "                          ])\n",
    "\n",
    "d_train = ImageFolder(\"dataset/train\", transform=transforms)\n",
    "train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
    "\n",
    "x_, y_ = next(iter(train_data))\n",
    "x_[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb42cda",
   "metadata": {},
   "source": [
    "### train \n",
    "обучение и сохранение весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2f9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], loss_mean=0.013: 100%|██████████| 1875/1875 [00:41<00:00, 44.93it/s]\n",
      "Epoch [2/15], loss_mean=0.014: 100%|██████████| 1875/1875 [00:41<00:00, 44.84it/s]\n",
      "Epoch [3/15], loss_mean=0.012: 100%|██████████| 1875/1875 [00:41<00:00, 44.71it/s]\n",
      "Epoch [4/15], loss_mean=0.013: 100%|██████████| 1875/1875 [00:40<00:00, 45.98it/s]\n",
      "Epoch [5/15], loss_mean=0.011: 100%|██████████| 1875/1875 [00:38<00:00, 48.55it/s]\n",
      "Epoch [6/15], loss_mean=0.013: 100%|██████████| 1875/1875 [00:40<00:00, 46.66it/s]\n",
      "Epoch [7/15], loss_mean=0.010: 100%|██████████| 1875/1875 [00:40<00:00, 46.42it/s]\n",
      "Epoch [8/15], loss_mean=0.012: 100%|██████████| 1875/1875 [00:40<00:00, 46.49it/s]\n",
      "Epoch [9/15], loss_mean=0.011: 100%|██████████| 1875/1875 [00:40<00:00, 46.65it/s]\n",
      "Epoch [10/15], loss_mean=0.009: 100%|██████████| 1875/1875 [00:40<00:00, 46.31it/s]\n",
      "Epoch [11/15], loss_mean=0.010: 100%|██████████| 1875/1875 [00:40<00:00, 46.66it/s]\n",
      "Epoch [12/15], loss_mean=0.010: 100%|██████████| 1875/1875 [00:40<00:00, 46.66it/s]\n",
      "Epoch [13/15], loss_mean=0.009: 100%|██████████| 1875/1875 [00:40<00:00, 46.24it/s]\n",
      "Epoch [14/15], loss_mean=0.011: 100%|██████████| 1875/1875 [00:40<00:00, 46.48it/s]\n",
      "Epoch [15/15], loss_mean=0.009: 100%|██████████| 1875/1875 [00:39<00:00, 47.13it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "epochs = 15\n",
    "model.train()\n",
    "\n",
    "for _e in range(epochs):\n",
    "    loss_mean = 0\n",
    "    lm_count = 0\n",
    "\n",
    "    train_tqdm = tqdm(train_data, leave=True)\n",
    "    for x_train, y_train in train_tqdm:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        predict = model(x_train)\n",
    "        loss = loss_function(predict, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lm_count += 1\n",
    "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "        train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575398e",
   "metadata": {},
   "source": [
    "## Restore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5237baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_weight_9930.pth', map_location='xpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967dbc0",
   "metadata": {},
   "source": [
    "### test\n",
    "результаты теста на обучающей выбрке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbb7619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993\n"
     ]
    }
   ],
   "source": [
    "d_test = ImageFolder(\"dataset/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test, batch_size=500, shuffle=False)\n",
    "\n",
    "Q = 0\n",
    "\n",
    "# тестирование обученной НС\n",
    "model.eval()\n",
    "\n",
    "for x_test, y_test in test_data:\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    with torch.no_grad():\n",
    "        p = model(x_test)\n",
    "        p = torch.argmax(p, dim=1)\n",
    "        Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3bae328",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfs.Compose([\n",
    "    tfs.ToImage(),\n",
    "    tfs.Resize((28, 28)),                  # подгоняем под MNIST\n",
    "    tfs.RandomInvert(p=1.0),               # инвертируем цвет\n",
    "    tfs.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "# transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed6cb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='xpu:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img = Image.open(\"images/im_2.png\")\n",
    "# img = img.convert(\"RGB\")\n",
    "# img = img.resize((28, 28))\n",
    "# # tr = tfs.Compose([tfs.RandomInvert(p=1.0), tfs.Grayscale()])\n",
    "# tr = tfs.Compose([tfs.RandomInvert(p=1.0)])\n",
    "# img = tr(img)\n",
    "# img = transform(img)\n",
    "# img = img.to(device)\n",
    "# torch.argmax(model(img.unsqueeze(0)).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970be5f7",
   "metadata": {},
   "source": [
    "### test\n",
    "тест на моих цифрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb650a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res\n",
    "        \n",
    "    \n",
    "res_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa710745",
   "metadata": {},
   "source": [
    "просмотр уверенности модели в предсказаниии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([  3.6321,  -2.1246, -13.9486, -18.4705,  -8.3152,  -6.9032,  -0.3296,\n",
      "         -2.7854,  -8.4743,  -6.7365], device='xpu:0')\n",
      "1 tensor([ -7.6111,   6.2181, -11.9663,  -9.5169,  -4.4738, -12.4820,  -7.1528,\n",
      "          1.5680,  -7.9062,  -2.2942], device='xpu:0')\n",
      "2 tensor([ -8.4691,  -5.8030,   2.5879, -11.5956,  -4.8282, -18.5708,  -7.4111,\n",
      "         -1.3404,  -8.8063,  -5.6595], device='xpu:0')\n",
      "3 tensor([ -4.5415,  -3.5830,  -3.5534,   3.5652, -13.9064,   1.2549,  -6.8555,\n",
      "         -0.8526, -10.5845,  -6.9299], device='xpu:0')\n",
      "4 tensor([-12.5873,  -6.8186,  -7.5927, -10.7364,  10.9016, -12.4248,  -7.2388,\n",
      "         -2.5142, -11.1034,   2.5333], device='xpu:0')\n",
      "5 tensor([ -6.0750,  -4.3300,  -7.9720,  -6.4201, -10.7675,   4.3451,  -5.1946,\n",
      "         -1.1657, -13.3159,  -4.7784], device='xpu:0')\n",
      "6 tensor([ -5.5584,  -7.9332, -14.0776, -10.0952, -10.1072,   3.7810,   4.3265,\n",
      "        -12.3465,  -5.2583,  -9.6533], device='xpu:0')\n",
      "7 tensor([-11.7895,   1.0425,  -9.7480,  -5.3131,  -3.0485, -13.1074,  -3.9278,\n",
      "          2.5649,  -7.1591,  -1.4769], device='xpu:0')\n",
      "8 tensor([-15.1641,  -8.9422, -12.3261,  -7.6529, -11.5647,  -6.8246,  -4.4576,\n",
      "         -8.9498,   9.7120,  -8.6996], device='xpu:0')\n",
      "9 tensor([-12.8230,  -6.3283,  -5.6111,  -2.2728,  -1.7505,  -3.3658,  -6.8271,\n",
      "         -6.8420,  -3.7043,  -0.6215], device='xpu:0')\n"
     ]
    }
   ],
   "source": [
    "# просмотр уверенности модели в предсказаниии\n",
    "\n",
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        print(i, res)\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df819db6",
   "metadata": {},
   "source": [
    "В результате ряда экспериментов подобрана модель и приведен пример распознавания цифр не из обучающей выборки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
