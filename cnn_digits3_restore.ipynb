{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce788329",
   "metadata": {},
   "source": [
    "# Распознавание рукописных цифр\n",
    "В данной работе напишу нейронку на базе Pytorch CNN для распознавания собственных рукописных цифр. Сложность в том что, обученная сеть на MNIST на моих цифрах показывает низкие результаты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c2b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Python3\\PyIntel\\img_transform\\Digits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd()) # current way\n",
    "# directory = os.path.join(os.path.dirname(__file__), \"my_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da01403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms.v2 as tfs\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06353c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: xpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch, \"xpu\") and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# xpu\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79df02",
   "metadata": {},
   "source": [
    "## Model\n",
    "здесь в результате тестов подобрана максимально эффективная модель для моих рукописных цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9faa5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model2 = nn.Sequential(\n",
    "    nn.Conv2d(3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2),\n",
    "\n",
    "    nn.Conv2d(16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Conv2d(32, out_channels=20, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(20),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2), # batch, out, 7, 7\n",
    "\n",
    "    nn.Flatten(1), # batch, 980\n",
    "    nn.Linear(20*7*7, 16, bias=False),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "\n",
    "    nn.Linear(16, 16, bias=False),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(16, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b06b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace=True)\n",
       "  (10): Conv2d(32, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (11): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (14): Flatten(start_dim=1, end_dim=-1)\n",
       "  (15): Linear(in_features=980, out_features=16, bias=False)\n",
       "  (16): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (17): ReLU(inplace=True)\n",
       "  (18): Linear(in_features=16, out_features=16, bias=False)\n",
       "  (19): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = conv_model2\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adee7d0",
   "metadata": {},
   "source": [
    "### формирование обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b4c515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms = tfs.Compose([tfs.ToImage(),\n",
    "                          tfs.ToDtype(torch.float32, scale=True),\n",
    "                          ])\n",
    "\n",
    "d_train = ImageFolder(\"dataset/train\", transform=transforms)\n",
    "train_data = data.DataLoader(d_train, batch_size=32, shuffle=True)\n",
    "\n",
    "x_, y_ = next(iter(train_data))\n",
    "x_[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb42cda",
   "metadata": {},
   "source": [
    "### train \n",
    "обучение и сохранение весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2f9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], loss_mean=0.251: 100%|██████████| 1875/1875 [00:43<00:00, 43.32it/s]\n",
      "Epoch [2/30], loss_mean=0.057: 100%|██████████| 1875/1875 [00:39<00:00, 47.16it/s]\n",
      "Epoch [3/30], loss_mean=0.044: 100%|██████████| 1875/1875 [00:40<00:00, 46.36it/s]\n",
      "Epoch [4/30], loss_mean=0.037: 100%|██████████| 1875/1875 [00:39<00:00, 47.06it/s]\n",
      "Epoch [5/30], loss_mean=0.032: 100%|██████████| 1875/1875 [00:39<00:00, 47.08it/s]\n",
      "Epoch [6/30], loss_mean=0.028: 100%|██████████| 1875/1875 [00:40<00:00, 46.79it/s]\n",
      "Epoch [7/30], loss_mean=0.025: 100%|██████████| 1875/1875 [00:39<00:00, 46.97it/s]\n",
      "Epoch [8/30], loss_mean=0.023: 100%|██████████| 1875/1875 [00:39<00:00, 47.25it/s]\n",
      "Epoch [9/30], loss_mean=0.021: 100%|██████████| 1875/1875 [00:39<00:00, 46.98it/s]\n",
      "Epoch [10/30], loss_mean=0.019: 100%|██████████| 1875/1875 [00:39<00:00, 47.03it/s]\n",
      "Epoch [11/30], loss_mean=0.018: 100%|██████████| 1875/1875 [00:39<00:00, 47.15it/s]\n",
      "Epoch [12/30], loss_mean=0.017: 100%|██████████| 1875/1875 [00:39<00:00, 47.21it/s]\n",
      "Epoch [13/30], loss_mean=0.014: 100%|██████████| 1875/1875 [00:39<00:00, 47.10it/s]\n",
      "Epoch [14/30], loss_mean=0.015: 100%|██████████| 1875/1875 [00:39<00:00, 47.24it/s]\n",
      "Epoch [15/30], loss_mean=0.013: 100%|██████████| 1875/1875 [00:39<00:00, 46.93it/s]\n",
      "Epoch [16/30], loss_mean=0.012: 100%|██████████| 1875/1875 [00:40<00:00, 46.26it/s]\n",
      "Epoch [17/30], loss_mean=0.011: 100%|██████████| 1875/1875 [00:39<00:00, 46.99it/s]\n",
      "Epoch [18/30], loss_mean=0.011: 100%|██████████| 1875/1875 [00:39<00:00, 47.22it/s]\n",
      "Epoch [19/30], loss_mean=0.011: 100%|██████████| 1875/1875 [00:40<00:00, 46.80it/s]\n",
      "Epoch [20/30], loss_mean=0.010: 100%|██████████| 1875/1875 [00:39<00:00, 46.89it/s]\n",
      "Epoch [21/30], loss_mean=0.009: 100%|██████████| 1875/1875 [00:39<00:00, 46.92it/s]\n",
      "Epoch [22/30], loss_mean=0.010: 100%|██████████| 1875/1875 [00:40<00:00, 46.20it/s]\n",
      "Epoch [23/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:40<00:00, 46.72it/s]\n",
      "Epoch [24/30], loss_mean=0.008: 100%|██████████| 1875/1875 [00:40<00:00, 46.60it/s]\n",
      "Epoch [25/30], loss_mean=0.009: 100%|██████████| 1875/1875 [00:39<00:00, 47.03it/s]\n",
      "Epoch [26/30], loss_mean=0.008: 100%|██████████| 1875/1875 [00:40<00:00, 46.71it/s]\n",
      "Epoch [27/30], loss_mean=0.008: 100%|██████████| 1875/1875 [00:40<00:00, 46.70it/s]\n",
      "Epoch [28/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:39<00:00, 46.96it/s]\n",
      "Epoch [29/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:38<00:00, 48.37it/s]\n",
      "Epoch [30/30], loss_mean=0.007: 100%|██████████| 1875/1875 [00:39<00:00, 48.03it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "epochs = 30\n",
    "model.train()\n",
    "\n",
    "for _e in range(epochs):\n",
    "    loss_mean = 0\n",
    "    lm_count = 0\n",
    "\n",
    "    train_tqdm = tqdm(train_data, leave=True)\n",
    "    for x_train, y_train in train_tqdm:\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        predict = model(x_train)\n",
    "        loss = loss_function(predict, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lm_count += 1\n",
    "        loss_mean = 1/lm_count * loss.item() + (1 - 1/lm_count) * loss_mean\n",
    "        train_tqdm.set_description(f\"Epoch [{_e+1}/{epochs}], loss_mean={loss_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575398e",
   "metadata": {},
   "source": [
    "## Restore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2bbd344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# torch.save(model.state_dict(), f'model_1_weight_{int(Q*10000)}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5237baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_weight_9930.pth', map_location='xpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b967dbc0",
   "metadata": {},
   "source": [
    "### test\n",
    "результаты теста на обучающей выбрке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb7619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993\n"
     ]
    }
   ],
   "source": [
    "d_test = ImageFolder(\"dataset/test\", transform=transforms)\n",
    "test_data = data.DataLoader(d_test, batch_size=500, shuffle=False)\n",
    "\n",
    "Q = 0\n",
    "\n",
    "# тестирование обученной НС\n",
    "model.eval()\n",
    "\n",
    "for x_test, y_test in test_data:\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    with torch.no_grad():\n",
    "        p = model(x_test)\n",
    "        p = torch.argmax(p, dim=1)\n",
    "        Q += torch.sum(p == y_test).item()\n",
    "\n",
    "Q /= len(d_test)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3bae328",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfs.Compose([\n",
    "    tfs.ToImage(),\n",
    "    tfs.Resize((28, 28)),                  # подгоняем под MNIST\n",
    "    tfs.RandomInvert(p=1.0),               # инвертируем цвет\n",
    "    tfs.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "# transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed6cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(\"images/im_2.png\")\n",
    "# img = img.convert(\"RGB\")\n",
    "# img = img.resize((28, 28))\n",
    "# # tr = tfs.Compose([tfs.RandomInvert(p=1.0), tfs.Grayscale()])\n",
    "# tr = tfs.Compose([tfs.RandomInvert(p=1.0)])\n",
    "# img = tr(img)\n",
    "# img = transform(img)\n",
    "# img = img.to(device)\n",
    "# torch.argmax(model(img.unsqueeze(0)).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970be5f7",
   "metadata": {},
   "source": [
    "### test\n",
    "тест на моих цифрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb650a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res\n",
    "        \n",
    "    \n",
    "res_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa710745",
   "metadata": {},
   "source": [
    "просмотр уверенности модели в предсказаниии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac24f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([  0.7973,  -6.5548,  -7.0180, -18.9206,  -8.3460,  -6.1676,  -2.9512,\n",
      "         -2.2850, -13.6281, -11.0323], device='xpu:0')\n",
      "1 tensor([-13.1169,   4.6537, -13.5996, -12.4463, -14.4070,  -8.9870, -13.2534,\n",
      "          0.3256, -14.2725, -11.6112], device='xpu:0')\n",
      "2 tensor([-10.5356,  -7.0368,   9.8484,  -8.2798,  -9.3443, -17.9443, -11.4218,\n",
      "          0.4944, -13.3453,  -9.4240], device='xpu:0')\n",
      "3 tensor([-12.5134,  -2.8164, -10.5482,  11.2100, -13.8626, -10.3312, -14.5341,\n",
      "         -3.5596, -14.6161, -13.2917], device='xpu:0')\n",
      "4 tensor([-10.2602,  -8.4368,  -4.6739, -13.8474,   5.7549,  -6.1382,  -7.3269,\n",
      "         -3.9511,  -9.6605,  -3.0228], device='xpu:0')\n",
      "5 tensor([-10.7049,  -5.1367,  -8.9492,  -6.9515, -14.6891,   7.1869,  -5.7139,\n",
      "        -10.5207,  -6.8137,  -7.7989], device='xpu:0')\n",
      "6 tensor([ -7.3206, -10.6756,  -1.5794, -11.5748,  -9.0165,   0.5516,   8.2982,\n",
      "         -8.7794, -10.8787, -11.5371], device='xpu:0')\n",
      "7 tensor([-18.8902,  -5.5793,  -8.1804,  -7.5899, -12.1642, -18.4566, -11.6392,\n",
      "         10.5379, -13.2601, -12.7833], device='xpu:0')\n",
      "8 tensor([-18.0591,  -9.1696,  -4.4365,  -6.3421,  -8.8430,  -3.5447,  -6.8637,\n",
      "        -10.2161,   5.8189, -11.6646], device='xpu:0')\n",
      "9 tensor([-8.5711, -6.0508, -1.5425, -2.1175, -1.3505,  0.5562, -3.9360, -5.5439,\n",
      "        -5.5101,  1.4689], device='xpu:0')\n"
     ]
    }
   ],
   "source": [
    "# просмотр уверенности модели в предсказаниии\n",
    "\n",
    "res_test = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(10):\n",
    "        img = Image.open(f\"images/im_{i}.png\")\n",
    "        img = img.convert(\"RGB\")\n",
    "        tensor_img = transform(img)\n",
    "        tensor_img = tensor_img.to(device)\n",
    "        # res = model(tensor_img)\n",
    "        res = model(tensor_img.unsqueeze(0)).squeeze()\n",
    "        print(i, res)\n",
    "        # res = res.softmax(dim=0) # .sort(descending=True)\n",
    "        res = torch.argmax(res)\n",
    "        res_test[i] = res.item()\n",
    "        # res_test[i] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df819db6",
   "metadata": {},
   "source": [
    "В результате ряда экспериментов подобрана модель и приведен пример распознавания цифр не из обучающей выборки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
